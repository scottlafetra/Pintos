       	       	    +---------------------------+
		    |		CS 140		|
		    | PROJECT 3: VIRTUAL MEMORY	|
		    |	   DESIGN DOCUMENT	|
		    +---------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Scott La Fetra
Alex Riley

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			PAGE TABLE MANAGEMENT
			=====================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

// Entries for the swap table. Each entry contains a virtual address
// prefix and the physical address it should be mapped to.
struct st_entry
{
  struct hash_elem h_elem;
  struct list_elem l_elem;
  struct sema sema_lock; // To allow multiple reads but not when changing the table
  u_int32 v_addr; // virtual page address
  void* p_addr; // physical page address
}

// "Table" that holds data for eviction. The accessed and dirty bits are accessed
// through the relevant pintos functions, so no actually hash table is necessary
// here.
struct frame_table
{
  struct st_entry* evict_next;
  struct st_entry* clock_ptr; // Used to turn off the access bit periodically
  u_int32 stack_end;
}

// Tracks open and used memory in the swap partition. These are kept in
// separate structs for quick access to the next free entry
struct swap_table
{
  struct list open; // A table of st_entry. Hashed by v_addr
  struct hash used; // A table of st_entry. Hashed by v_addr
}

// Page table entry. Maps virtual addresses to physical addresses
struct pt_entry
{
  struct hash_elem elem;
  u_int32 v_addr;
  u_int32 p_addr;
}

// The page table. Just contains a hash table of elements for translation.
struct page_table
{
  struct list table; // A table of pt_entry. Hashed by v_addr
}

// Supplemental page table entry. Tracks ownership of each page by process id.
struct supt_entry
{
  struct hash_elem elem;
  pid_t pid;
}

// The supplemental page table. Just contains a hash table of page ownership.
struct sup_table
{
  struct list table; // A table of pt_entry. Hashed by v_addr
}


---- ALGORITHMS ----

>> A2: In a few paragraphs, describe your code for locating the frame,
>> if any, that contains the data of a given page.

A user program asks for a page by it's virtual address. This goes to the (virtual) page_table where it is mapped to the correct frame index of the frame_table.
	If the page is on the frame_table we return it.
If the page isn't on the frame_table then we check the swap table.
	If it is on the swap then we allocate a new frame for it on the frame_table, return it's address to the user program, and then free the swap slot. 
	If it isn't on the swap then we go back to the frame_table and we grab the data from the hard drive, allocating a new space for it on the frame_table. We then return it.

>> A3: How does your code coordinate accessed and dirty bits between
>> kernel and user virtual addresses that alias a single frame, or
>> alternatively how do you avoid the issue?

Dirty bits are owned by the kernel virtual page table which the frame table interacts with. The frame table reads these bits from the kernel virtual page table and evicts based on that.

---- SYNCHRONIZATION ----

>> A4: When two user processes both need a new frame at the same time,
>> how are races avoided?

We use a semaphore to allow any amount of threads to read at the same time if no thread is trying to write, but only one thread to have access if we are writing or evicting a frame. If a thread wants to write it is forced to wait until all reading threads have finished reading before it can write. In the meantime no other threads can start reading or writing until the writing thread is done. This protects us from writing at the same time as well as sneaking a read in right before a frame will be evicted. It also allows multiple threads to read simultaneously without locking each other out.

---- RATIONALE ----

>> A5: Why did you choose the data structure(s) that you did for
>> representing virtual-to-physical mappings?



		       PAGING TO AND FROM DISK
		       =======================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

// Entries for the swap table. Each entry contains a virtual address
// prefix and the physical address it should be mapped to.
struct st_entry
{
  struct hash_elem elem;
  struct sema sema_lock; // To allow multiple reads but not when changing the table
  u_int32 v_addr; // virtual page address
  void* p_addr; // physical page address
}

// "Table" that holds data for eviction. The accessed and dirty bits are accessed
// through the relevant pintos functions, so no actually hash table is necessary
// here.
struct frame_table
{
  struct ft_entry* evict_next;
  struct ft_entry* clock_ptr; // Used to turn off the access bit periodically
  u_int32 stack_end;
}

// Tracks open and used memory in the swap partition. These are kept in
// separate structs for quick access to the next free entry
struct swap_table
{
  struct list open; // A table of ft_entry. Hashed by v_addr
  struct hash used; // A table of ft_entry. Hashed by v_addr
}

---- ALGORITHMS ----

>> B2: When a frame is required but none is free, some frame must be
>> evicted.  Describe your code for choosing a frame to evict.

We are using the clock method for eviction. We keep track of two pointers to frames evict_next and clock_ptr. Whenever we a new frame but we are out of memory we move the evict_next up until we find a frame that isn't accessed (which we check in the kernel virtual page table). We evict the frame that hasn't been accessed since the clock_ptr passed it. We also move up the clock_ptr at the same time changing all frames we pass over to be non-accessed. 

>> B3: When a process P obtains a frame that was previously used by a
>> process Q, how do you adjust the page table (and any other data
>> structures) to reflect the frame Q no longer has?



>> B4: Explain your heuristic for deciding whether a page fault for an
>> invalid virtual address should cause the stack to be extended into
>> the page that faulted.



---- SYNCHRONIZATION ----

>> B5: Explain the basics of your VM synchronization design.  In
>> particular, explain how it prevents deadlock.  (Refer to the
>> textbook for an explanation of the necessary conditions for
>> deadlock.)

We only lock on write, and a thread shouldn't do anything else while writing. We also only use one semaphore per frame so there shouldn't be any oppertunity for deadlocks simply by the fact that threads only have one lock at a time. 

>> B6: A page fault in process P can cause another process Q's frame
>> to be evicted.  How do you ensure that Q cannot access or modify
>> the page during the eviction process?  How do you avoid a race
>> between P evicting Q's frame and Q faulting the page back in?

We use a semaphore to allow any amount of threads to read at the same time if no thread is trying to write, but only one thread to have access if we are writing or evicting a frame. If a thread wants to write it is forced to wait until all reading threads have finished reading before it can write. In the meantime no other threads can start reading or writing until the writing thread is done. This protects us from writing at the same time as well as sneaking a read in right before a frame will be evicted. It also allows multiple threads to read simultaneously without locking each other out.

>> B7: Suppose a page fault in process P causes a page to be read from
>> the file system or swap.  How do you ensure that a second process Q
>> cannot interfere by e.g. attempting to evict the frame while it is
>> still being read in?

We keep frames that are being read separate, and they are only added to the master table after they are fully read in. 

>> B8: Explain how you handle access to paged-out pages that occur
>> during system calls.  Do you use page faults to bring in pages (as
>> in user programs), or do you have a mechanism for "locking" frames
>> into physical memory, or do you use some other design?  How do you
>> gracefully handle attempted accesses to invalid virtual addresses?

We check the frame table, then swap, then all open files open for that process for the frame in question. If that faults then we take the frame in from Disk. Invalid pages are weeded out in the virtual page table as an invalid page will not be listed. In that case we just throw the error an error.

---- RATIONALE ----

>> B9: A single lock for the whole VM system would make
>> synchronization easy, but limit parallelism.  On the other hand,
>> using many locks complicates synchronization and raises the
>> possibility for deadlock but allows for high parallelism.  Explain
>> where your design falls along this continuum and why you chose to
>> design it this way.

We use semaphore locks for each entry. This allows multiple processes
can read the same entry, but requires that a process wait for all
reads to finish before changing the table. We chose this method because
it allowed for the most parallelism without unnessisary locks.

			 MEMORY MAPPED FILES
			 ===================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

// Memory map entry.
struct m_map_entry
{
  struct hash_elem elem;
  uint_t p_addr;
}

// A struct for holding a memory mapped file. We keep track of the
// size so when we evict the pages we only write the bits necessary
// to the file.
struct m_maped_file
{
  struct hash used_pages; // A table of pt_entry. Hashed by v_addr
  size_t size; // file size
}

---- ALGORITHMS ----

>> C2: Describe how memory mapped files integrate into your virtual
>> memory subsystem.  Explain how the page fault and eviction
>> processes differ between swap pages and other pages.

>> C3: Explain how you determine whether a new file mapping overlaps
>> any existing segment.

---- RATIONALE ----

>> C4: Mappings created with "mmap" have similar semantics to those of
>> data demand-paged from executables, except that "mmap" mappings are
>> written back to their original files, not to swap.  This implies
>> that much of their implementation can be shared.  Explain why your
>> implementation either does or does not share much of the code for
>> the two situations.

